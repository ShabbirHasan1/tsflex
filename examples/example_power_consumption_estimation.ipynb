{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d012ea3-cce3-47eb-86f8-2e936dd690ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import urllib.request as urllib2\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505740a",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "- [ ] Put all the imports at the top\n",
    "- [ ] Create a requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc845-1c78-415d-96bf-9658f4f62e96",
   "metadata": {},
   "source": [
    "# loading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798d3fe",
   "metadata": {},
   "source": [
    "This example uses the pulbic UCI [power consumption](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption) dataset.\n",
    "\n",
    "This dataset withholds measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a337e-5492-4e2f-9c57-7506d4a5bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_url: str = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\"\n",
    "zipped_file_name: str = \"household_power_consumption.txt\"\n",
    "\n",
    "\n",
    "df_power_consumption: pd.DataFrame = pd.read_csv(\n",
    "    ZipFile(BytesIO(urllib2.urlopen(zip_url).read())).open(zipped_file_name),\n",
    "    sep=\";\",\n",
    "    parse_dates={\"timestamp\": [\"Date\", \"Time\"]},\n",
    "    infer_datetime_format=True,\n",
    "    low_memory=False,\n",
    "    na_values=[\"nan\", \"?\"],\n",
    "    index_col=\"timestamp\",\n",
    "    dtype=\"float32\",\n",
    ")\n",
    "\n",
    "display(df_power_consumption.sample(3))\n",
    "df_power_consumption.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6491d-8c31-4bdb-af1a-655b253b0066",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caba702",
   "metadata": {},
   "source": [
    "**first step**: Reading the [dataset description](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption) (or gather all information about the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cc9ca-cc1e-4c2f-a12d-388a8f5b169f",
   "metadata": {},
   "source": [
    "**global variables**:\n",
    "* `global_active_power`: household global **minute averaged** active power (kilowatt)\n",
    "* `global_reactive_power`: household global **minute averaged** reactive power (kilowatt)\n",
    "* `global_intensity`: household global **minute averaged** current (ampere)\n",
    "* `voltage`: minute-averaged voltage (volt)\n",
    "\n",
    "**sub meterings**:\n",
    "* `sub_metering_1`: **kitchen** - dishwasher & microwave - (in watt-hour of **active energy**)\n",
    "* `sub_metering_2`: **laundry room** - washing maching, tumble drier, refrigerator & light (in watt-hour of **active energy**)\n",
    "* `sub_metering_3`: electric water-heater & air conditioner (in watt-hour of **active energy**)\n",
    "\n",
    "\n",
    "As the user is only billed for the **active power**, we will use this variable as target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84897e",
   "metadata": {},
   "source": [
    "## General data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power_consumption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power_consumption.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039c919-3d3b-4ecb-b948-e35ce9068b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'rows={df_power_consumption.shape[0]:,}', \n",
    "    f'cols={df_power_consumption.shape[1]:,}'\n",
    ")\n",
    "print('-'*80)\n",
    "# It appears we have some NaN's (not a numbers) in the data.\n",
    "print('NaN sum:')\n",
    "df_power_consumption.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power_consumption.describe().round(2).astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b513741-fb87-451f-afd3-f5c205491e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the data is actually regularly sampled\n",
    "df_power_consumption.index.to_series().diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8af785-a405-4258-952f-1321b5059dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# but if we drop the nan's (i.e. the isnull() values), this will not be the case\n",
    "df_power_consumption.dropna().index.to_series().diff().value_counts().sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e00063",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2127b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_power_consumption = df_power_consumption.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8bfff-767c-4e4d-8668-751cd8799019",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_power_consumption.corr() * np.tril(\n",
    "    np.ones(tuple([len(df_power_consumption.columns)] * 2)), k=-1\n",
    ")\n",
    "pd.set_option(\"precision\", 3)\n",
    "corr.style.background_gradient(cmap=\"coolwarm\", axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly_resampler import FigureResampler\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly_resampler.downsamplers import LTTB\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = FigureResampler(\n",
    "    make_subplots(\n",
    "        rows=3, cols=1, shared_xaxes=True,\n",
    "        specs=[[{'secondary_y': True}], [{}], [{'secondary_y': True}]],\n",
    "        subplot_titles=['Globals', 'Voltage', 'Sub metering']\n",
    "    ),\n",
    "    default_n_shown_samples=1000,\n",
    "    default_downsampler=LTTB(interleave_gaps=True),\n",
    ")\n",
    "\n",
    "for c, row, visible in [('Global_active_power', 1, 1), ('Global_reactive_power', 1, 'legendonly'), ('Voltage', 2, 1),\n",
    "    ('Sub_metering_1', 3, 1), ('Sub_metering_2', 3, 1), ('Sub_metering_3', 3, 1)]:\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=c, visible=visible),\n",
    "        hf_x=df_power_consumption.index,\n",
    "        hf_y=df_power_consumption[c],\n",
    "        row=row,\n",
    "        col=1\n",
    "    )\n",
    "\n",
    "for c in ['Global_intensity']:\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=c, visible='legendonly'),\n",
    "        hf_x=df_power_consumption.index,\n",
    "        hf_y=df_power_consumption[c],\n",
    "        secondary_y=True,\n",
    "        row=1,\n",
    "        col=1\n",
    "    )\n",
    "\n",
    "# add a shaded weekend region on the lowest row\n",
    "datelist = pd.date_range(df_power_consumption.index[0].date(), df_power_consumption.index[-1], freq='D')\n",
    "weekend = datelist.weekday.isin([5, 6]).astype(int)\n",
    "fig.add_trace(\n",
    "    go.Scattergl(line_shape='hv', name='Weekend', showlegend=False, line_color ='rgba(0,0,0,0)', fillcolor='rgba(99, 110, 250, 0.15)', fill='tozeroy'),\n",
    "    hf_x=datelist,\n",
    "    hf_y=weekend,\n",
    "    limit_to_view=True,\n",
    "    max_n_samples=len(weekend),\n",
    "    secondary_y=True,\n",
    "    row=3,\n",
    "    col=1\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(height=800)\n",
    "fig.show_dash(mode='external', port=8051)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b35f10",
   "metadata": {},
   "source": [
    "## Creating an objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a223f-6911-4218-a05c-30f72f59b67e",
   "metadata": {},
   "source": [
    "Our objective is:\n",
    "> Estimate the average `Global active power` over the last 15 minutes by **only** using past sub-metering values.\n",
    "\n",
    "`TODO` decide whether global intensity will be used<br>\n",
    "**remark**:\n",
    "We explicitly did not use global variables (like `global_intensity`) as these are show high correlations with the global power consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7aebbd-1865-4d39-ae20-1a59ba4a61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our client wants to know the average power consumption per 15 minutes and this\n",
    "# 5 minutes in advance for the next 15-minute period\n",
    "avg_window_min = 15\n",
    "shift_min = - (5 + avg_window_min)\n",
    "\n",
    "avg_col = f\"GAP_avg{avg_window_min}min\"\n",
    "target_col = f\"{avg_col}_shift{shift_min}min\"\n",
    "\n",
    "# create the target by (1) calculating the average and (2) shifting the data so we will forecast\n",
    "df_power_consumption[avg_col] = df_power_consumption.rolling(avg_window_min)[\"Global_active_power\"].aggregate(np.nanmean)\n",
    "df_power_consumption[target_col] = df_power_consumption[avg_col].shift(shift_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d2527",
   "metadata": {},
   "source": [
    " ### 🚨 Perform visual inspection 🔍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b350a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly_resampler import FigureResampler\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "fig = FigureResampler(make_subplots(rows=1, cols=1, shared_xaxes=True))\n",
    "\n",
    "for c, row, visible in [('Global_active_power', 1, 1), (avg_col, 1, 'legendonly'), (target_col, 1, 1)]:\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=c, visible=visible),\n",
    "        hf_x=df_power_consumption.index,\n",
    "        hf_y=df_power_consumption[c],\n",
    "        row=row,\n",
    "        col=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show_dash(mode='external', port=8051)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d357a6-bf82-4bec-9fac-ff50a7f7d80e",
   "metadata": {},
   "source": [
    "# ML time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d97733-846b-4d3f-97e8-c2698f5551f8",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f264fd-c547-4475-99de-391c0f9a1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [f\"Sub_metering_{i}\" for i in range(1, 4)] + [\"timestamp\", \"Global_intensity\", \"Voltage\"]\n",
    "target_col = target_col\n",
    "\n",
    "# The percentage of data used for testing\n",
    "test_pct = 0.2\n",
    "day_margin = 3\n",
    "\n",
    "# add the timestamp col\n",
    "df_power_consumption[\"timestamp\"] = df_power_consumption.index\n",
    "\n",
    "# Temporal split: Use the last test_pct of the data as test_data\n",
    "df_train = df_power_consumption[: -int(len(df_power_consumption) * test_pct)].copy()\n",
    "X_train, y_train = df_train[train_columns], df_train[target_col]\n",
    "\n",
    "df_test = df_power_consumption[df_train.index[-1] + pd.Timedelta(days=day_margin) :]\n",
    "X_test, y_test = df_test[train_columns], df_test[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301c660-9935-45f0-906c-63bf981f4299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f35e44-053e-4f47-978b-3b83f7599961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "from tsflex.chunking import chunk_data\n",
    "from tsflex.features import FeatureCollection, MultipleFeatureDescriptors\n",
    "from tsflex.features.utils import make_robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3558302-1cfb-4e26-8860-23ba725ff71e",
   "metadata": {},
   "source": [
    "## Feature extraction with tsflex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59791e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install holidays\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a98df-3467-48ca-8172-bc83e3540cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some feature functions\n",
    "def slope(x): return (x[-1] - x[0]) / x[0] if x[0] else 0\n",
    "def abs_diff_mean(x): return np.mean(np.abs(x[1:] - x[:-1])) if len(x) > 1 else 0\n",
    "def diff_std(x): return np.std(x[1:] - x[:-1]) if len(x) > 1 else 0\n",
    "\n",
    "\n",
    "# time based features\n",
    "def time_float(x) -> float:\n",
    "    x_ = pd.Timestamp(x[-1])\n",
    "    return np.float32(x_.hour + x_.minute / 60)\n",
    "\n",
    "def day_of_week(x) -> int: return pd.Timestamp(x[-1]).day_of_week\n",
    "\n",
    "def is_holiday(x) -> bool: return pd.Timestamp(x[-1]) in holidays.France()\n",
    "\n",
    "def yesterday_holiday(x) -> bool:\n",
    "    return (pd.Timestamp(x[-1]) - pd.Timedelta(days=1)) in holidays.France()\n",
    "\n",
    "def tomorrow_holiday(x) -> bool:\n",
    "    return (pd.Timestamp(x[-1]) - pd.Timedelta(days=1)) in holidays.France()\n",
    "\n",
    "funcs = [\n",
    "    make_robust(f)\n",
    "    for f in [ np.min, np.max, np.std, np.mean, slope, ss.skew, abs_diff_mean, diff_std,sum, len,]\n",
    "]\n",
    "time_funcs = [\n",
    "    make_robust(f)\n",
    "    for f in [time_float, day_of_week, is_holiday, yesterday_holiday, tomorrow_holiday]\n",
    "]\n",
    "\n",
    "# Create the feature collection\n",
    "fc = FeatureCollection(\n",
    "    feature_descriptors=[\n",
    "        MultipleFeatureDescriptors(\n",
    "            functions=funcs,\n",
    "            # TODO -> maybe also use the `intensity`\n",
    "            series_names=list(set(train_columns).difference({\"timestamp\"})),\n",
    "            windows=[\"15min\", \"30min\", \"1h\"],# \"6h\", \"12h\", \"24h\"],\n",
    "            strides=\"15min\",\n",
    "        ),\n",
    "        MultipleFeatureDescriptors(\n",
    "            functions=time_funcs,\n",
    "            series_names=\"timestamp\",\n",
    "            windows=[\"15min\"],\n",
    "            strides=\"15min\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73955641-f7d3-4178-b8ce-ee94306ca606",
   "metadata": {},
   "source": [
    "### Chunking train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb9cfe-09e7-42fc-b2ba-53e96e914af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# chunk the data in blocks of `max_chunk_dur`\n",
    "# also omits the gaps :)\n",
    "chunks = chunk_data(\n",
    "    data=df_train,\n",
    "    max_chunk_dur=\"365 days\",\n",
    "    chunk_range_margin=\"10 min\",\n",
    "    sub_chunk_overlap=\"15min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cabee-bb68-4d0f-8f8c-87949f43c73c",
   "metadata": {},
   "source": [
    "we will now use these yearly chunks to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0af4d-143c-4f16-afa9-a7c28df75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train_feats = pd.concat(\n",
    "    [\n",
    "        fc.calculate(chunk, show_progress=True, return_df=True, approve_sparsity=True, n_jobs=None)\n",
    "        for chunk in chunks\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be387195-2079-479c-a7cc-e8bdefa73506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b1e29-0387-4bf2-a8e5-e8385c46c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that there are no duplicate indices\n",
    "print(df_train_feats.shape)\n",
    "df_train_feats = df_train_feats[~df_train_feats.index.duplicated()]\n",
    "print(df_train_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b6a97-591c-49e2-a2f9-fc8752e060c8",
   "metadata": {},
   "source": [
    "## Constructing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2747077-cd2d-48b1-991e-4e28aeda39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = df_train_feats.columns\n",
    "df_train = df_train_feats.join(y_train)\n",
    "# drop the observations of which we don't have the target\n",
    "df_train = df_train[df_train[y_train.name].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518ba75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f081df-715d-41cf-bad8-495ae009313d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = catboost.CatBoostRegressor(verbose=100, )\n",
    "\n",
    "# as this is a lot of data, this might take a minute or 5\n",
    "pipe.fit(df_train[selected_cols], df_train[y_train.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06745adf-030a-429c-89b8-c13ad41ff1e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbdb2a-3d9a-4279-905c-3f3b47a21805",
   "metadata": {},
   "source": [
    "## Prediction on `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25daeea2-4fe0-4fc0-ae39-3b3c672620df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_feats = fc.calculate(\n",
    "    df_test, show_progress=True, return_df=True, approve_sparsity=True,n_jobs=None\n",
    ").dropna(how='all', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6acf6-8211-4fb8-b768-c2c6f7c988ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tot = df_test_feats.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35862894-c301-4fe6-bdd2-72e18ac8bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe.predict(df_test_tot[selected_cols])\n",
    "df_test_tot[\"predictions\"] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be473433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats_ = df_train_feats.join(y_train)\n",
    "train_predictions = pipe.predict(df_train_feats_[selected_cols])\n",
    "nan_mask = df_train_feats_[y_train.name].notna()\n",
    "y_true, y_pred = df_train_feats_[y_train.name][nan_mask], train_predictions[nan_mask]\n",
    "\n",
    "print(\"MSE  [TRAIN]: \", round(mean_squared_error(y_true, y_pred), 3))\n",
    "print(\"MAE  [TRAIN]: \", round(mean_absolute_error(y_true, y_pred), 3))\n",
    "print(\"MAPE [TRAIN]: \", round(mean_absolute_percentage_error(y_true, y_pred), 3))\n",
    "print(\"R2   [TRAIN]: \", round(r2_score(y_true, y_pred), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_mask = df_test_tot[y_test.name].notna()\n",
    "y_true, y_pred = df_test_tot[nan_mask][y_test.name], df_test_tot[nan_mask][\"predictions\"]\n",
    "\n",
    "print(\"MSE  [TEST]: \", round(mean_squared_error(y_true, y_pred), 3))\n",
    "print(\"MAE  [TEST]: \", round(mean_absolute_error(y_true, y_pred), 3))\n",
    "print(\"MAPE [TEST]: \", round(mean_absolute_percentage_error(y_true, y_pred), 3))\n",
    "print(\"R2   [TEST]: \", round(r2_score(y_true, y_pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33312237",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c3adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "explainer = shap.TreeExplainer(pipe)\n",
    "shap_values = explainer.shap_values(df_train_feats[selected_cols])\n",
    "shap.summary_plot(shap_values, df_train_feats[selected_cols], max_display=50, \n",
    "                    auto_size_plot=True, show=False, color_bar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals= np.abs(shap_values).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(selected_cols, vals)),columns=['col_name','feature_importance_vals'])\n",
    "feature_importance = feature_importance.sort_values(by=['feature_importance_vals'],ascending=False).reset_index(drop=True)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "important_cols = feature_importance[:n]['col_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88aef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac639b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm_pipe = Pipeline([\n",
    "#     ('scaler', PowerTransformer()),\n",
    "#     ('gmm', GaussianMixture(n_components=25, covariance_type='diag', random_state=42)),\n",
    "# ])\n",
    "# gmm_pipe.fit(df_train_feats[important_cols].dropna(how='any'))\n",
    "# loglh = gmm_pipe.score_samples(df_test_feats[important_cols].dropna(how='any'))\n",
    "# loglh = pd.Series(index=df_test_feats[important_cols].dropna(how='any').index, data=loglh)\n",
    "\n",
    "# AE = (df_test_tot['predictions'] - df_test_tot[y_test.name]).abs()\n",
    "\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "# joined = AE.rename('MAE').to_frame().join((loglh * -1).rename('loglh')).dropna(how='any')\n",
    "# pearsonr(joined.MAE, joined.loglh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd834c-8adc-4183-ad35-a5fd3406e358",
   "metadata": {},
   "source": [
    "## Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba558aeb-3d8d-43d5-81cc-50e951bd3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_upper = catboost.CatBoostRegressor(verbose=100, loss_function='Quantile:alpha=0.975')\n",
    "pipe_lower = catboost.CatBoostRegressor(verbose=100, loss_function='Quantile:alpha=0.025')\n",
    "\n",
    "pipe_upper.fit(df_train[selected_cols], df_train[y_train.name])\n",
    "pipe_lower.fit(df_train[selected_cols], df_train[y_train.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5693f62-5451-448d-a88e-1dad9dbb324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PICP(y_true,y_lower,y_upper):\n",
    "    return np.logical_and(y_lower<=y_true, y_true<=y_upper).sum()/len(y_true)*100\n",
    "    \n",
    "def NMPIW(y_true,y_lower,y_upper):\n",
    "    return np.mean(y_upper-y_lower)/(np.max(y_true)-np.min(y_true))\n",
    "    \n",
    "def MPIW(y_true,y_lower,y_upper):\n",
    "    return np.mean(y_upper-y_lower)\n",
    "\n",
    "#def pred_Crossing(y_pred,y_lower,y_upper):\n",
    "#    return np.logical_or(y_upper<y_pred,y_pred<y_lower).sum()/len(y_true)*100\n",
    "\n",
    "#def quantile_Crossing(y_lower,y_upper):\n",
    "#    return (y_upper<y_lower).sum()/len(y_true)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4ee43-c944-49e3-9dd3-c5b135970727",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_upper = pipe_upper.predict(df_train_feats_[selected_cols])\n",
    "train_predictions_lower = pipe_lower.predict(df_train_feats_[selected_cols])\n",
    "\n",
    "nan_mask = df_train_feats_[y_train.name].notna()\n",
    "y_true, y_pred_upper, y_pred_lower = df_train_feats_[y_train.name][nan_mask], train_predictions_upper[nan_mask], train_predictions_lower[nan_mask]\n",
    "\n",
    "print(\"[TEST] PICP = \"+str(np.round(PICP(y_true.values,y_pred_lower,y_pred_upper),2))+\" % -- NMPIW = \"+str(np.round(NMPIW(y_true.values,y_pred_lower,y_pred_upper),2))+\" -- MPIW = \"+str(np.round(MPIW(y_true.values,y_pred_lower,y_pred_upper),2))+\" kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acf5de-35f9-445d-a3db-40b267e52283",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_upper = pipe_upper.predict(df_test_tot[selected_cols])\n",
    "out_lower = pipe_lower.predict(df_test_tot[selected_cols])\n",
    "\n",
    "df_test_tot[\"predictions_upper\"] = out_upper\n",
    "df_test_tot[\"predictions_lower\"] = out_lower\n",
    "\n",
    "nan_mask = df_test_tot[y_test.name].notna()\n",
    "y_true, y_pred_upper, y_pred_lower = df_test_tot[nan_mask][y_test.name], df_test_tot[nan_mask][\"predictions_upper\"], df_test_tot[nan_mask][\"predictions_lower\"]\n",
    "\n",
    "print(\"[TEST] PICP = \"+str(np.round(PICP(y_true.values,y_pred_lower.values,y_pred_upper.values),2))+\" % -- NMPIW = \"+str(np.round(NMPIW(y_true.values,y_pred_lower.values,y_pred_upper.values),2))+\" -- MPIW = \"+str(np.round(MPIW(y_true.values,y_pred_lower.values,y_pred_upper.values),2))+\" kW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03855696",
   "metadata": {},
   "source": [
    "## Visualizing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88161a53-e122-4a33-b80a-e086c9222d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objecats as go\n",
    "from plotly_resampler.downsamplers import EveryNthPoint \n",
    "\n",
    "fig = FigureResampler(make_subplots(rows=2, shared_xaxes=True, specs=[[{}], [{'secondary_y': True}]]), default_n_shown_samples=1000)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattergl(name='target'),\n",
    "    hf_x=y_test.index, hf_y=y_test, row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattergl(name=\"predictions\", marker_color=\"red\"),\n",
    "    hf_x=df_test_tot.index, hf_y=df_test_tot.predictions, row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_test_tot.index,\n",
    "        y=df_test_tot.predictions_upper,\n",
    "        name=\"upper_bound\",\n",
    "        showlegend=False,\n",
    "        marker_color='black',\n",
    "        line=dict(width=0),\n",
    "        mode='lines',\n",
    "    ),\n",
    "    downsampler=EveryNthPoint(),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df_test_tot.index,\n",
    "        y=df_test_tot.predictions_lower,\n",
    "        name=\"lower bound\",\n",
    "        showlegend=False,\n",
    "        marker_color='black',\n",
    "        line=dict(width=0),\n",
    "        mode='lines',\n",
    "        fillcolor='rgba(255, 0, 0, 0.2)',\n",
    "        fill='tonexty'\n",
    "    ),\n",
    "    downsampler=EveryNthPoint(),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(title=\"Power consumption predictions\", title_x=0.5, hovermode='x')\n",
    "fig.update_xaxes(title=\"Time\")\n",
    "fig.update_yaxes(title=\"AVG power consumption (kW)\")\n",
    "fig.show_dash(mode='external', height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c3e3a",
   "metadata": {},
   "source": [
    "**notes**:\n",
    "* this notebook is far from complete and serves as \"quick\" first iteration:\n",
    "  * using a linear model as baseline\n",
    "  * trying other windows / strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce471d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc.serialize('fc.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "058975938d2190a16515f75fca60e764787758da52be5bbf3c711d7cb37de623"
  },
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
